{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vYiZq0X2oB5t"
   },
   "source": [
    "# **CSCE 5218 / CSCE 4930 Deep Learning**\n",
    "\n",
    "# **HW1a The Perceptron** (20 pt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGVmKzgG2Ium",
    "outputId": "4cc2ca21-861a-4fba-a38c-83e3ec04bec8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-02-06 19:48:50--  http://huang.eng.unt.edu/CSCE-5218/test.dat\n",
      "Resolving huang.eng.unt.edu (huang.eng.unt.edu)... 129.120.123.155\n",
      "Connecting to huang.eng.unt.edu (huang.eng.unt.edu)|129.120.123.155|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2844 (2.8K)\n",
      "Saving to: ‘test.dat’\n",
      "\n",
      "test.dat            100%[===================>]   2.78K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-06 19:48:51 (284 MB/s) - ‘test.dat’ saved [2844/2844]\n",
      "\n",
      "--2022-02-06 19:48:51--  http://huang.eng.unt.edu/CSCE-5218/train.dat\n",
      "Resolving huang.eng.unt.edu (huang.eng.unt.edu)... 129.120.123.155\n",
      "Connecting to huang.eng.unt.edu (huang.eng.unt.edu)|129.120.123.155|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11244 (11K)\n",
      "Saving to: ‘train.dat’\n",
      "\n",
      "train.dat           100%[===================>]  10.98K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-02-06 19:48:51 (64.4 MB/s) - ‘train.dat’ saved [11244/11244]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the datasets\n",
    "!wget http://huang.eng.unt.edu/CSCE-5218/test.dat\n",
    "!wget http://huang.eng.unt.edu/CSCE-5218/train.dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A69DxPSc8vNs",
    "outputId": "5440e602-8ecd-44cf-d48d-2e8b00cdcc52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\t\n",
      "1\t1\t0\t0\t0\t0\t0\t0\t1\t1\t0\t0\t1\t0\n",
      "0\t0\t1\t1\t0\t1\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t1\t0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t1\n",
      "0\t0\t1\t0\t0\t1\t0\t1\t0\t1\t1\t1\t1\t0\n",
      "0\t1\t0\t0\t0\t0\t0\t1\t1\t1\t1\t1\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t0\t1\t0\t1\t1\t0\t1\t1\n",
      "0\t1\t1\t0\t0\t0\t1\t0\t0\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t1\t1\t0\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t0\t0\t0\t0\t0\t1\t0\t1\t0\t1\t0\t1\t0\n",
      "A1\tA2\tA3\tA4\tA5\tA6\tA7\tA8\tA9\tA10\tA11\tA12\tA13\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t0\t0\t1\t0\t0\t1\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t1\t1\t1\t1\t0\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t1\t0\t1\t1\t1\t0\t1\t0\t1\t0\n",
      "0\t1\t0\t0\t0\t1\t0\t1\t0\t1\t0\t0\t1\t0\n",
      "0\t1\t1\t0\t0\t1\t1\t1\t1\t1\t1\t0\t1\t0\n",
      "0\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t1\t1\t0\n",
      "0\t1\t0\t0\t1\t0\t0\t1\t1\t0\t1\t1\t1\t0\n",
      "1\t1\t1\t1\t0\t0\t1\t1\t0\t0\t0\t0\t1\t0\n"
     ]
    }
   ],
   "source": [
    "# Take a peek at the datasets\n",
    "!head train.dat\n",
    "!head test.dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFXHLhnhwiBR"
   },
   "source": [
    "### Build the Perceptron Model\n",
    "\n",
    "You will need to complete some of the function definitions below.  DO NOT import any other libraries to complete this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "cXAsP_lw3QwJ"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "\n",
    "# Corpus reader, all columns but the last one are coordinates;\n",
    "#   the last column is the label\n",
    "def read_data(file_name):\n",
    "    f = open(file_name, 'r')\n",
    "\n",
    "    data = []\n",
    "    # Discard header line\n",
    "    f.readline()\n",
    "    for instance in f.readlines():\n",
    "        if not re.search('\\t', instance): continue\n",
    "        instance = list(map(int, instance.strip().split('\\t')))\n",
    "        # Add a dummy input so that w0 becomes the bias\n",
    "        instance = [-1] + instance\n",
    "        data += [instance]\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def dot_product(array1, array2):\n",
    "    arr=0\n",
    "    for i in range(len(array1)):\n",
    "      arr+=array1[i]*array2[i]\n",
    "    return arr \n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    e=math.exp(-x)\n",
    "    sigm=1/(1+e)\n",
    "    return sigm\n",
    "\n",
    "# The output of the model, which for the perceptron is \n",
    "# the sigmoid function applied to the dot product of \n",
    "# the instance and the weights\n",
    "def output(weight, instance):\n",
    "    output= sigmoid(dot_product(weight, instance))\n",
    "    return output\n",
    "\n",
    "# Predict the label of an instance; this is the definition of the perceptron\n",
    "# you should output 1 if the output is >= 0.5 else output 0\n",
    "def predict(weights, instance):\n",
    "    #TODO: return the prediction of the model\n",
    "    out=output(weights, instance)\n",
    "    if(out>=0.5):\n",
    "      out=1\n",
    "    else:\n",
    "      out=0\n",
    "    return out\n",
    "\n",
    "\n",
    "# Accuracy = percent of correct predictions\n",
    "def get_accuracy(weights, instances):\n",
    "    # You do not to write code like this, but get used to it\n",
    "    correct = sum([1 if predict(weights, instance) == instance[-1] else 0\n",
    "                   for instance in instances])\n",
    "    return correct * 100 / len(instances)\n",
    "\n",
    "\n",
    "# Train a perceptron with instances and hyperparameters:\n",
    "#       lr (learning rate) \n",
    "#       epochs\n",
    "# The implementation comes from the definition of the perceptron\n",
    "#\n",
    "# Training consists on fitting the parameters which are the weights\n",
    "# that's the only thing training is responsible to fit\n",
    "# (recall that w0 is the bias, and w1..wn are the weights for each coordinate)\n",
    "#\n",
    "# Hyperparameters (lr and epochs) are given to the training algorithm\n",
    "# We are updating weights in the opposite direction of the gradient of the error,\n",
    "# so with a \"decent\" lr we are guaranteed to reduce the error after each iteration.\n",
    "\n",
    "def train_perceptron(instances, lr, epochs):\n",
    "\n",
    "    #TODO: name this step => initializing initial weights to zeros\n",
    "    weights = [0] * (len(instances[1])-1)\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for instance in instances:\n",
    "\n",
    "            #TODO: name these steps : Initilizing the input values and calculating output and error\n",
    "            in_value = dot_product(weights, instance)\n",
    "            output = sigmoid(in_value)\n",
    "            error = instance[-1] - output\n",
    "\n",
    "            #TODO: name these steps : Adjusting the weights accordingly\n",
    "            for i in range(0, len(weights)):\n",
    "                weights[i] += lr * error * output * (1-output) * instance[i]\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adBZuMlAwiBT"
   },
   "source": [
    "## Run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "50YvUza-BYQF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "lr = 0.005\n",
    "epochs = 5\n",
    "weights = train_perceptron(instances_tr, lr, epochs)\n",
    "accuracy = get_accuracy(weights, instances_te)\n",
    "print(f\"#tr: {len(instances_tr):3}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "      f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CBXkvaiQMohX"
   },
   "source": [
    "## Questions\n",
    "\n",
    "Answer the following questions. Include your implementation and the output for each question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YCQ6BEk1CBlr"
   },
   "source": [
    "\n",
    "\n",
    "### Question 1\n",
    "\n",
    "In `train_perceptron(instances, lr, epochs)`, we have the follosing code:\n",
    "```\n",
    "in_value = dot_product(weights, instance)\n",
    "output = sigmoid(in_value)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "Why don't we have the following code snippet instead?\n",
    "```\n",
    "output = predict(weights, instance)\n",
    "error = instance[-1] - output\n",
    "```\n",
    "\n",
    "#### TODO Add your answer here (text only)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. According to the activation function Y=mX+c\n",
    "    (Y is the output, m is the weights , x are instances,\n",
    "    c is bias).\n",
    "    the predict function gives the best values. ie 0 or 1 \n",
    "    if output >=0.5 the output will be 1\n",
    "    if output <0.5 output will be 0.So it cannot be used as\n",
    "    an output.\n",
    "    Also Sigmoid activation function accepts the value between 0\n",
    "    and 1 . here we have used it to get better perceptron model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JU3c3m6YL2rK"
   },
   "source": [
    "### Question 2\n",
    "Train the perceptron with the following hyperparameters and calculate the accuracy with the test dataset.\n",
    "\n",
    "```\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]              # number of epochs\n",
    "lr = [0.005, 0.01, 0.05]              # learning rate\n",
    "```\n",
    "\n",
    "TODO: Write your code below and include the output at the end of each training loop (NOT AFTER EACH EPOCH)\n",
    "of your code.The output should look like the following:\n",
    "```\n",
    "# tr:  20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "# tr:  20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "[and so on for all the combinations]\n",
    "```\n",
    "You will get different results with different hyperparameters.\n",
    "\n",
    "#### TODO Add your answer here (code and output in the format above) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G-VKJOUu2BTp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#tr: 20, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 67.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.005; Accuracy (test, 100 instances): 73.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 20, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 71.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.010; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.010; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.010; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.010; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.010; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 20, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 20, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 64.0\n",
      "#tr: 40, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 40, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
      "#tr: 40, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 100, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 68.0\n",
      "#tr: 100, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 67.0\n",
      "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
      "#tr: 100, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 100, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 200, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
      "#tr: 200, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 200, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 200, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 200, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
      "#tr: 300, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 74.0\n",
      "#tr: 300, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 300, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 79.0\n",
      "#tr: 300, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 78.0\n",
      "#tr: 300, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 77.0\n",
      "#tr: 400, epochs:   5, learning rate: 0.050; Accuracy (test, 100 instances): 69.0\n",
      "#tr: 400, epochs:  10, learning rate: 0.050; Accuracy (test, 100 instances): 76.0\n",
      "#tr: 400, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs:  50, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n",
      "#tr: 400, epochs: 100, learning rate: 0.050; Accuracy (test, 100 instances): 80.0\n"
     ]
    }
   ],
   "source": [
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]     # number of epochs\n",
    "lr_array = [0.005, 0.01, 0.05]        # learning rate\n",
    "\n",
    "for lr in lr_array:\n",
    "  for tr_size in tr_percent:\n",
    "    for epochs in num_epochs:\n",
    "      size =  round(len(instances_tr)*tr_size/100)\n",
    "      pre_instances = instances_tr[0:size]\n",
    "      weights = train_perceptron(pre_instances, lr, epochs)\n",
    "      accuracy = get_accuracy(weights, instances_te)\n",
    "      print(f\"#tr: {len(pre_instances):0}, epochs: {epochs:3}, learning rate: {lr:.3f}; \"\n",
    "            f\"Accuracy (test, {len(instances_te)} instances): {accuracy:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFB9MtwML24O"
   },
   "source": [
    "### Question 3\n",
    "Write a couple paragraphs interpreting the results with all the combinations of hyperparameters. Drawing a plot will probably help you make a point. In particular, answer the following:\n",
    "- A. Do you need to train with all the training dataset to get the highest accuracy with the test dataset?\n",
    "- B. How do you justify that training the second run obtains worse accuracy than the first one (despite the second one uses more training data)?\n",
    "   ```\n",
    "#tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 71.0\n",
    "#tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "```\n",
    "- C. Can you get higher accuracy with additional hyperparameters (higher than `80.0`)?\n",
    "- D. Is it always worth training for more epochs (while keeping all other hyperparameters fixed)?\n",
    "\n",
    "#### TODO: Add your answer here (code and text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy/Learning Rate(X/Y)')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "instances_tr = read_data(\"train.dat\")\n",
    "instances_te = read_data(\"test.dat\")\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] # percent of the training dataset to train with\n",
    "num_epochs = [5, 10, 20, 50, 100]     # number of epochs\n",
    "lr_array = [0.005, 0.01, 0.05]        # learning rate\n",
    "acc=[]\n",
    "lr_=[]\n",
    "epo=[]\n",
    "tr=[]\n",
    "for lr in lr_array:\n",
    "  for tr_size in tr_percent:\n",
    "    for epochs in num_epochs:\n",
    "      size =  round(len(instances_tr)*tr_size/100)\n",
    "      pre_instances = instances_tr[0:size]\n",
    "      weights = train_perceptron(pre_instances, lr, epochs)\n",
    "      accuracy = get_accuracy(weights, instances_te)\n",
    "      tr.append(len(pre_instances))\n",
    "      lr_.append(lr)\n",
    "      acc.append(accuracy)\n",
    "      epo.append(epochs)\n",
    "fi,(ax1, ax2) = plt.subplots(1, 2)\n",
    "a=[]\n",
    "b=[]\n",
    "i=0\n",
    "while(i<5):\n",
    "  a.append(max(acc[i::5]))\n",
    "  b.append(max(epo[i::5]))\n",
    "  i+=1\n",
    "c=[]\n",
    "d=[]\n",
    "i=0\n",
    "while(i<3):\n",
    "  c.append(max(acc[(30*i):(30*(i+1))]))\n",
    "  d.append(max(lr_[(30*i):(30*(i+1))]))\n",
    "  i+=1\n",
    "ax1.plot(a, b, label = \"Max accuracy\", linestyle=\"-\",color=\"green\")\n",
    "ax2.plot(c, d, label = \"Max accuracy\", linestyle=\"-\",color=\"red\")\n",
    "\n",
    "ax1.set_title(\"Accuracy/Epoches(X/Y)\")\n",
    "ax2.set_title(\"Accuracy/Learning Rate(X/Y)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "ANSWER:\n",
    "\n",
    "A. Yes. As we increase the training rate the data also increases and as a result the accuracy also increases.\n",
    "Let's understand with the example\n",
    "tr_percent = [5, 10, 25, 50, 75, 100] tr_percent implies percentage of the dataset\n",
    "\n",
    "#tr: 20, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "#tr: 200, epochs: 100, learning rate: 0.005; Accuracy (test, 100 instances): 74.0\n",
    "\n",
    "   So , As the percentage increases training rate increases and so does the accuracy.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "B.Outputs:\n",
    "    \n",
    "   #tr: 100, epochs:  20, learning rate: 0.050; Accuracy (test, 100 instances): 70.0\n",
    "    #tr: 200, epochs:  20, learning rate: 0.005; Accuracy (test, 100 instances): 68.0\n",
    "    \n",
    "    \n",
    "Considering the outputs the training rate is decreased but the learning rate has been increased so accuracy is High in this case.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "   C.NO,The Data is non Linear,so we cannot getmore accuracy by adding more parameters.\n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   \n",
    "   D. Actually it depends.It is not always suggested to increase epoches ,because sometimes if the epoches are increased greater than requirement ,the system may become overfitting . But in our case as the data is underfitted so it is useful to train for additional epochs by maintaining all hyper parameters constant\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW2_The_Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
